{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc0dbe7",
   "metadata": {},
   "source": [
    "<div class=\"licence\">\n",
    "<span><img src=\"media/logo_IPParis.png\" /></span>\n",
    "<span>Lisa BEDIN<br />Pierre André CORNILLON<br />Eric MATZNER-LOBER</span>\n",
    "<span>Licence CC BY-NC-ND</span>\n",
    "</div>\n",
    "\n",
    "# Modules\n",
    "\n",
    "Importer les modules pandas (comme `pd`) numpy (commme `np`) le sous module `pyplot` de `matplotlib` comme `plt` les fonctions `StandardScaler` de `sklearn.preprocessing`, `Lasso` de `sklearn.linear_model`, `LassoCV` de `sklearn.linear_model`, `ElasticNet` de `sklearn.linear_model`, `ElasticNetCV` de `sklearn.linear_model`, `cross_val_predict` de `sklearn.model_selection`, `KFold` de `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f966f",
   "metadata": {},
   "source": [
    "# Régression lasso sur les données d'ozone\n",
    "\n",
    "\n",
    "## Importation des données\n",
    "\n",
    "Importer les données d'ozone `ozonecomplet.csv` et éliminer les deux dernières variables (qualitatives) et faites un résumé numérique par variable [méthode `astype` sur la colonne du DataFrame et méthode `describe` sur l'instance DataFrame\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5ba87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone = pd.read_csv(\"data/ozonecomplet.csv\", header=0, sep=\";\")\n",
    "ozone = ozone.drop(['nomligne', 'Ne', 'Dv'], axis=1)\n",
    "ozone.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a994a4c",
   "metadata": {},
   "source": [
    "## Création des tableaux `numpy`\n",
    "\n",
    "avec l'aide des méthodes d'instance `iloc` ou `loc` créer les tableaux `numpy` `y` et `X` (on se servira de l'attribut `values` qui donne le tableau `numpy` sous-jascent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ozone.O3.values\n",
    "X = ozone.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2181a5",
   "metadata": {},
   "source": [
    "## Centrage et réduction\n",
    "\n",
    "Centrer et réduire les variable avec `StandardScaler` selon le schéma suivant\n",
    "\n",
    "1.  créer une instance avec la fonction `StandardScaler`. On notera `scalerX` l'instance créée.\n",
    "2.  l'ajuster via la méthode d'instance `fit` (calcul des moyennes et écart-types) et avec le tableau `numpy` des $X$\n",
    "3.  Transformer le tableau $X$ en tableau centré réduit via la méthode d'instance `transform` et avec le tableau `numpy` des $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX = StandardScaler().fit(X)\n",
    "Xcr= scalerX.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073678d1",
   "metadata": {},
   "source": [
    "## Evolution des coefficients selon $\\lambda$\n",
    "\n",
    "La fonction `LassoCV` va donner directement la grille de $\\lambda$ (contrairement à ridge). Utiliser cette fonction sur les données centrées réduites pour récupérer la grille (attribut `alphas_`). Avec cette grille faire un boucle pour estimer les coefficients $\\hat\\beta(\\lambda)$ pour chaque valeur de $\\lambda$\n",
    "\n",
    "Ajustons le modèle pour chaque valeur de $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ec064",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = LassoCV().fit(Xcr,y)\n",
    "alphas_lasso = rl.alphas_\n",
    "lcoef = []\n",
    "for ll in alphas_lasso:\n",
    "    rl = Lasso(alpha=ll).fit(Xcr,y)\n",
    "    lcoef.append(rl.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def62729",
   "metadata": {},
   "source": [
    "et traçons les coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(alphas_lasso), lcoef)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe181a4",
   "metadata": {},
   "source": [
    "On voit que pour une certaine valeur de $\\lambda$ (ici 22) tous les coefficients sont nuls.\n",
    "\n",
    "\n",
    "## Choix du $\\hat \\lambda$ optimal (par validation croisée 10 blocs/fold)\n",
    "\n",
    "En séparant le jeu de données en 10 Blocs grâce à la fonction [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) (l'instance de `KFold` sera nommée `kf`) trouver le $\\hat \\lambda$ optimal avec un score \"somme des erreurs quadratiques par bloc\" ; utiliser `cross_val_predict` (la grille devra être fournie à `Lasso`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "res = pd.DataFrame(np.zeros((X.shape[0], len(alphas_lasso))))\n",
    "for j, ll in enumerate(alphas_lasso):\n",
    "    res.iloc[:,j] = cross_val_predict(Lasso(alpha=ll),Xcr,y,cv=kf)\n",
    "sse = res.apply(lambda x: ((x-y)**2).sum(), axis=0)\n",
    "print(alphas_lasso[sse.argmin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1909f19",
   "metadata": {},
   "source": [
    "## Retrouver les résultats de la question précédente\n",
    "\n",
    "Avec la fonction `LassoCV` et l'objet `kf` retrouver le $\\hat \\lambda$ optimal (par validation croisée 10 blocs/fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cadc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = LassoCV(cv=kf).fit(Xcr, y)\n",
    "print(rl.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fea099",
   "metadata": {},
   "source": [
    "    0.7727174033372736\n",
    "\n",
    "Ici la fonction objectif est le $\\mathrm{R}^2$ par bloc (et pas la somme des écarts quadratiques) et on retrouve le même $\\hat \\lambda$ (ce qui n'est pas garanti dans tous les cas…)\n",
    "\n",
    "\n",
    "## Prévision\n",
    "\n",
    "Utiliser la régression ridge avec $\\hat \\lambda$ optimal pour prévoir la concentration d'ozone pour $x^*=(18, 18, 18 ,5 ,5 , 6, 5 ,-4 ,-3, 90)'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8af817",
   "metadata": {},
   "outputs": [],
   "source": [
    "xet = np.array([[18, 18, 18 ,5 ,5 , 6, 5 ,-4 ,-3, 90]])\n",
    "xetcr = scalerX.transform(xet)\n",
    "print(rl.predict(xetcr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a87a1",
   "metadata": {},
   "source": [
    "    [85.28390512]\n",
    "\n",
    "\n",
    "# Elastic-Net\n",
    "\n",
    "refaire avec les mêmes données les questions de l'exercice précédent avec une balance entre norme 1 et norme 2 de 1/2 (`l1_ratio`).\n",
    "\n",
    "\n",
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone = pd.read_csv(\"data/ozonecomplet.csv\", header=0, sep=\";\")\n",
    "ozone = ozone.drop(['nomligne', 'Ne', 'Dv'], axis=1)\n",
    "ozone.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c1cec",
   "metadata": {},
   "source": [
    "## Création des tableaux `numpy`\n",
    "\n",
    "avec l'aide des méthodes d'instance `iloc` ou `loc` créer les tableaux `numpy` `y` et `X` (on se servira de l'attribut `values` qui donne le tableau `numpy` sous-jascent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ozone.O3.values\n",
    "X = ozone.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ed39a",
   "metadata": {},
   "source": [
    "## Centrage et réduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14534cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX = StandardScaler().fit(X)\n",
    "Xcr= scalerX.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb215d",
   "metadata": {},
   "source": [
    "## Evolution des coefficients selon $\\lambda$\n",
    "\n",
    "Ajustons le modèle pour chaque valeur de $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "ren = ElasticNetCV().fit(Xcr,y)\n",
    "alphas_elasticnet = ren.alphas_\n",
    "lcoef = []\n",
    "for ll in alphas_elasticnet:\n",
    "    ren = ElasticNet(alpha=ll).fit(Xcr,y)\n",
    "    lcoef.append(ren.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ad727",
   "metadata": {},
   "source": [
    "et traçons les coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47386c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(alphas_elasticnet), lcoef)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adfcf4",
   "metadata": {},
   "source": [
    "On voit que les coefficients en général décroissent (en valeur absolue) quand la pénalité augmente.\n",
    "\n",
    "\n",
    "## Choix du $\\hat \\lambda$ optimal (par validation croisée 10 blocs/fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "res = pd.DataFrame(np.zeros((X.shape[0], len(alphas_elasticnet))))\n",
    "for j, ll in enumerate(alphas_elasticnet):\n",
    "    res.iloc[:,j] = cross_val_predict(ElasticNet(alpha=ll),Xcr,y,cv=kf)\n",
    "sse = res.apply(lambda x: ((x-y)**2).sum(), axis=0)\n",
    "print(alphas_elasticnet[sse.argmin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574f56a",
   "metadata": {},
   "source": [
    "## Retrouver les résultats de la question précédente\n",
    "\n",
    "Avec la fonction `ElasticNetCV` et l'objet `kf` retrouver le $\\hat \\lambda$ optimal (par validation croisée 10 blocs/fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ren = ElasticNetCV(cv=kf).fit(Xcr, y)\n",
    "print(ren.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b32441",
   "metadata": {},
   "source": [
    "    0.41048105093488396\n",
    "\n",
    "Ici la fonction objectif est le $\\mathrm{R}^2$ par bloc (et pas la somme des écarts quadratiques) et on retrouve le même $\\hat \\lambda$ (ce qui n'est pas garanti dans tous les cas…)\n",
    "\n",
    "\n",
    "## Prévision\n",
    "\n",
    "Utiliser la régression ridge avec $\\hat \\lambda$ optimal pour prévoir la concentration d'ozone pour $x^*=(18, 18, 18 ,5 ,5 , 6, 5 ,-4 ,-3, 90)'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "xet = np.array([[18, 18, 18 ,5 ,5 , 6, 5 ,-4 ,-3, 90]])\n",
    "xetcr = scalerX.transform(xet)\n",
    "print(ren.predict(xetcr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee455a00",
   "metadata": {},
   "source": [
    "    [87.15292087]\n",
    "\n",
    "Pas le même modèle ici donc pas la même prévision."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all, -hidden, -heading_collapsed, -run_control, -trusted",
   "notebook_metadata_filter": "all, -jupytext.text_representation.jupytext_version, -jupytext.text_representation.format_version, -language_info.version, -language_info.codemirror_mode.version, -language_info.codemirror_mode, -language_info.file_extension, -language_info.mimetype, -toc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "nbhosting": {
   "title": "Correction du TP Lasso et Elastic-Net",
   "version": "1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
