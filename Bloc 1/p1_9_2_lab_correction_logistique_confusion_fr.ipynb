{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8285a5a8",
   "metadata": {},
   "source": [
    "---\n",
    "jupytext:\n",
    "  cell_metadata_filter: all, -hidden, -heading_collapsed, -run_control, -trusted\n",
    "  notebook_metadata_filter: all, -jupytext.text_representation.jupytext_version, -jupytext.text_representation.format_version, -language_info.version, -language_info.codemirror_mode.version, -language_info.codemirror_mode, -language_info.file_extension, -language_info.mimetype, -toc\n",
    "  text_representation:\n",
    "    extension: .md\n",
    "    format_name: myst\n",
    "kernelspec:\n",
    "  display_name: Python 3 (ipykernel)\n",
    "  language: python\n",
    "  name: python3\n",
    "language_info:\n",
    "  name: python\n",
    "  nbconvert_exporter: python\n",
    "  pygments_lexer: ipython3\n",
    "nbhosting:\n",
    "  title: 'Correction du TP régression Logistique: seuil et matrice de confusion'\n",
    "  version: '1.0'\n",
    "---\n",
    "\n",
    "<div class=\"licence\">\n",
    "<span><img src=\"media/logo_IPParis.png\" /></span>\n",
    "<span>Lisa BEDIN<br />Pierre André CORNILLON<br />Eric MATZNER-LOBER</span>\n",
    "<span>Licence CC BY-NC-ND</span>\n",
    "</div>\n",
    "\n",
    "# Modules python\n",
    "\n",
    "Importer les modules pandas (comme `pd`) numpy (commme `np`) matplotlib.pyplot (comme `plt`) et statsmodels.formula.api (comme `smf`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8efaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29465021",
   "metadata": {},
   "source": [
    "# Régression logistique (suite TP précédent)\n",
    "\n",
    "\n",
    "## Importation des données\n",
    "\n",
    "Importer les données `artere.txt` dans le DataFrame pandas `artere` \\[`read_csv` de `numpy` \\]. Sur Fun Campus le chemin est `data/artere.txt`. Outre l'age et la présence=1/absence=0 de la maladie cardio-vasculaire (`chd`) une variable qualitative à 8 modalités donne les classes d'age (`agegrp`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe17357",
   "metadata": {},
   "outputs": [],
   "source": [
    "artere = pd.read_csv(\"data/artere.txt\", header=0, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d126964",
   "metadata": {},
   "source": [
    "## Régression logistique\n",
    "\n",
    "Effectuer une régression logistique où `age` est la variable explicative et `chd` la variable binaire à expliquer. Stocker le résultat dans l'objet `modele`\n",
    "\n",
    "\\[`logit` de `smf`, méthode `fit` \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03420a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele = smf.logit('chd~age', data=artere).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ec8ca",
   "metadata": {},
   "source": [
    "## Matrice de confusion (ajustée)\n",
    "\n",
    "Afficher la matrice de confusion estimée sur les données de l'échantillon pour un seuil choisi à 0.5.\n",
    "\n",
    "Une méthode manuelle est la suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = modele.predict()>0.5\n",
    "df = pd.DataFrame({\"yhat\" : yhat, \"chd\": artere.chd})\n",
    "pd.crosstab(index=df['chd'], columns=df['yhat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac28b5",
   "metadata": {},
   "source": [
    "mais il existe aussi une fonction adptée uniquement à l'estimation de la matrice de confusion en ajustement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.pred_table(threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c42b1",
   "metadata": {},
   "source": [
    "Attention cette matrice de confusion est ajustée et reste donc très optimiste. Une matrice de confusion calculée par validation croisée ou apprentissage/validation est plus que conseillée !\n",
    "\n",
    "\n",
    "## Résidus\n",
    "\n",
    "Représenter graphiquement les résidus de déviance avec\n",
    "\n",
    "1.  en abscisse la variable `age` et en ordonnée les résidus \\[attribut `resid_dev` du modèle\\];\n",
    "2.  en abscisse le numéro de ligne du tableau (index) après permutation aléatoire et en ordonnées les résidus.\n",
    "\n",
    "\\[`plt.plot`, méthode `predict` pour l'instance/modèle ajusté et `np.arange` pour générer les numéros de ligne avec l'attribut `shape` du DataFrame ; créer une instance de générateur aléatoire `np.random.default_rng` et utiliser `rng.permutation` sur les numéros de ligne\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036299d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(artere.age, modele.resid_dev, \"+\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2438fc5",
   "metadata": {},
   "source": [
    "Nous retrouvons l'allure caractéristique du graphique résidus fonction de $\\hat p$ (ou de l'age ici). Ce type de graphique n'est pas utilisé en pratique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=1234)\n",
    "indexp = rng.permutation(np.arange(artere.shape[0]))\n",
    "plt.plot(indexp, modele.resid_dev, \"+\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492185de",
   "metadata": {},
   "source": [
    "Aucune observation avec des valeurs extrêmes, le modèle ajuste bien les données.\n",
    "\n",
    "\n",
    "## Matrice de confusion (en prévision)\n",
    "\n",
    "Ayant peu de données ici plutôt que d'évaluer la matrice de confusion en apprentissage/validation nous choisissons (contraints et forcés) d'évaluer celle-ci en validation croisée.\n",
    "\n",
    "\n",
    "### Séparation en 10 blocs\n",
    "\n",
    "Nous allons séparer le jeu de données en 10 blocs grâce à la fonction [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) (du module `sklearn` sous module `model_selection`) créer une instance de `StratifiedKFold` nommée `skf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c677a",
   "metadata": {},
   "source": [
    "Cela permet d'obtenir une répartition 0/1 quasiment identique de blocs en blocs. En effet la proportion de 1 dans chaque bloc de validation est ici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = artere.chd.values\n",
    "X = artere.values\n",
    "for app_index, val_index in skf.split(X,y):\n",
    "    print(val_index)\n",
    "    print(artere.chd.iloc[val_index].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd03b5",
   "metadata": {},
   "source": [
    "### DataFrame prevision et $chd$\n",
    "\n",
    "Créer un DataFrame `res` avec deux colonnes: la variable $chd$ et une second colonne remplie de 0 qui contiendra les prévisions. Cette colonne pourra être nommée `yhat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(artere.chd)\n",
    "res[\"yhat\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31c495",
   "metadata": {},
   "source": [
    "Ajouter au fur et à mesure les prévisions en validation croisée dans la deuxième colonne: Pour chaque «tour» de bloc faire\n",
    "\n",
    "1.  estimer sur les 9 blocs en apprentissage le modèle de régression logistique\n",
    "2.  prévoir les données du bloc en validation (seuil $s=1/2$)\n",
    "3.  ranger dans les lignes correspondantes de `res` les prévisions (dans la colonne `yhat`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ce719",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = artere.chd.values\n",
    "X = artere.iloc[:,0:2].values\n",
    "s = 0.5\n",
    "for app_index, val_index in skf.split(X,y):\n",
    "    artereapp=artere.iloc[app_index,:]\n",
    "    artereval=artere.iloc[val_index,:]\n",
    "    modele = smf.logit('chd~age', data=artereapp).fit()\n",
    "    res.iloc[val_index,1] = modele.predict(exog=artereval)>s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47194ab1",
   "metadata": {},
   "source": [
    "### Calculer la matrice de confusion\n",
    "\n",
    "Avec la fonction `crosstab` du module `pd` proposer la matrice de confusion estimée par validation croisée. En déduire la spécifité et la sensibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(index=res['chd'], columns=res['yhat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478e062",
   "metadata": {},
   "source": [
    "## Choix d'un seuil\n",
    "\n",
    "Un test physique réalise une sensibilité de 50% et pour cette sensibilité une spécifité de $90\\%$. Choisir le seuil pour une sensibilité de 50% (en validation croisée 10 blocs) et donner la spécifité correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d992eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sall = np.linspace(0, 1 , 100)\n",
    "res = np.zeros((artere.shape[0], len(sall)+1))\n",
    "res[:,0] = artere.chd.values\n",
    "res = pd.DataFrame(res)\n",
    "res.rename(columns={res.columns[0] : \"chd\"}, inplace=True)\n",
    "for i,s in enumerate(sall):\n",
    "    for app_index, val_index in skf.split(X,y):\n",
    "        artereapp=artere.iloc[app_index,:]\n",
    "        artereval=artere.iloc[val_index,:]\n",
    "        modele = smf.logit('chd~age', data=artereapp).fit()\n",
    "        res.iloc[val_index,i+1] = modele.predict(exog=artereval)>s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051ff6f",
   "metadata": {},
   "source": [
    "On calcule pour chaque seuil les matrices de confusion (attention au cas où le modèle ne prévoit que des \"0\" ou que des \"1\").\n",
    "\n",
    "De tous les seuils qui dépassent 0.5 de sensibilité prenons le plus grand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a61f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = pd.DataFrame(np.zeros((len(sall),2)))\n",
    "for i,s in enumerate(sall):\n",
    "    tab = pd.crosstab(index=res['chd'], columns=res.iloc[:,i+1])\n",
    "    if tab.shape[1]==1:\n",
    "        if tab.columns[0]:\n",
    "            confusion.iloc[i, 0]=0\n",
    "            confusion.iloc[i, 1]=1\n",
    "        else:\n",
    "            confusion.iloc[i, 0]=1\n",
    "            confusion.iloc[i, 1]=0\n",
    "    else:\n",
    "        confusion.iloc[i, 0] = tab.iloc[0,0]/ tab.iloc[0,:].sum()\n",
    "        confusion.iloc[i, 1] = tab.iloc[1,1]/ tab.iloc[1,:].sum()\n",
    "\n",
    "print(sall[confusion.loc[confusion.iloc[:,1]>=0.5].shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57520230",
   "metadata": {},
   "source": [
    "Ce modèle d'age permet ici un sensibilité de 0.5 et presque 0.9 de spécifité.\n",
    "\n",
    "\n",
    "# Choix de variables\n",
    "\n",
    "\n",
    "## Importation des données\n",
    "\n",
    "Importation des données d'ozone `spambase.data` (dans Fun Campus les données sont dans le répertoire `data/`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2156412",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"data/spambase.data\", header=None,  sep=\",\")\n",
    "spam.rename(columns={spam.columns[57] : \"Y\"}, inplace=True)\n",
    "namestr = [\"X\"+str(i) for i in spam.columns[0:57] ]\n",
    "spam.rename(columns= dict(zip(list(spam.columns[0:57]), namestr)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f3547",
   "metadata": {},
   "source": [
    "## Sélection descendante/backward\n",
    "\n",
    "Nous reprenons le code de sélection descendante sur la régression et nous remplaçons simplement le mot `ols` par `logit`\n",
    "\n",
    "La fonction commence avec le modèle complet.\n",
    "\n",
    "-   Nous séparons la variable réponse (objet `response`) des variables explicatives,\n",
    "-   Ces dernières sont transformées en un ensemble (objet `start_explanatory`),\n",
    "-   L'ensemble le plus petit est l'ensemble vide (objet `lower_explanatory`),\n",
    "-   Les variables potentielles à supprimer sont obtenues par différence (objet `remove`),\n",
    "\n",
    "Nous initialisons l'ensemble des variables sélectionnées (objet `selected`) et réalisons notre première formule en utilisant toutes les variables sélectionnées. En utilisant `smf.logit` nous obtenons l'AIC ou le BIC du modèle de départ (`current_score`).\n",
    "\n",
    "La boucle while commence :\n",
    "\n",
    "-   pour chaque variable (boucle for) à supprimer, nous effectuons une régression avec l'ensemble actuel des variables moins cette variable candidate. Nous construisons une liste de triplets `score` (AIC/BIC), signe (toujours \"-\" car nous effectuons une sélection backward) et la variable candidate à supprimer du modèle actuel.\n",
    "\n",
    "-   A la fin de la boucle for, nous trions toute la liste des triplets en utilisant le score et si le meilleur triplet a un `score` meilleur que `current_score` nous mettons à jour `remove`, `selected` et `current_score`, si ce n'est pas le cas, nous interrompons la boucle while.\n",
    "\n",
    "A la fin, nous ajustons le modèle actuel et le renvoyons comme résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logitbackward(data, start, crit=\"aic\", verbose=False):\n",
    "    \"\"\"Backward selection for linear model with smf (with formula).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data (pandas DataFrame): DataFrame with all possible predictors\n",
    "            and response\n",
    "    start (string): a string giving the starting model\n",
    "            (ie the starting point)\n",
    "    crit (string): \"aic\"/\"AIC\" or \"bic\"/\"BIC\"\n",
    "    verbose (boolean): if True verbose print\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" linear model fitted with statsmodels\n",
    "           with an intercept and\n",
    "           selected by forward/backward or both algorithm with crit criterion\n",
    "    \"\"\"\n",
    "    # criterion\n",
    "    if not (crit == \"aic\" or crit == \"AIC\" or crit == \"bic\" or crit == \"BIC\"):\n",
    "        raise ValueError(\"criterion error (should be AIC/aic or BIC/bic)\")\n",
    "    # starting point\n",
    "    formula_start = start.split(\"~\")\n",
    "    response = formula_start[0].strip()\n",
    "    # explanatory variables for the 3 models\n",
    "    start_explanatory = set([item.strip() for item in\n",
    "                             formula_start[1].split(\"+\")]) - set(['1'])\n",
    "    # setting up the set \"remove\" which contains the possible\n",
    "    # variable to remove\n",
    "    lower_explanatory = set([])\n",
    "    remove = start_explanatory - lower_explanatory\n",
    "    # current point\n",
    "    selected = start_explanatory\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(list(selected)))\n",
    "    if crit == \"aic\" or crit == \"AIC\":\n",
    "        current_score = smf.logit(formula, data).fit().aic\n",
    "    elif crit == \"bic\" or crit == \"BIC\":\n",
    "        current_score = smf.logit(formula, data).fit().bic\n",
    "    if verbose:\n",
    "        print(\"----------------------------------------------\")\n",
    "        print((current_score, \"Starting\", selected))\n",
    "    # main loop\n",
    "    while True:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remove:\n",
    "            tobetested = selected - set([candidate])\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(list(tobetested)))\n",
    "            if crit == \"aic\" or crit == \"AIC\":\n",
    "                score = smf.logit(formula, data).fit().aic\n",
    "            elif crit == \"bic\" or crit == \"BIC\":\n",
    "                score = smf.logit(formula, data).fit().bic\n",
    "            if verbose:\n",
    "                print((score, \"-\", candidate))\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop(0)\n",
    "        if current_score > best_new_score:\n",
    "            remove = remove - set([best_candidate])\n",
    "            selected = selected - set([best_candidate])\n",
    "            current_score = best_new_score\n",
    "            if verbose:\n",
    "                print(\"----------------------------------------------\")\n",
    "                print((current_score, \"New Current\", selected))\n",
    "        else:\n",
    "            break\n",
    "    if verbose:\n",
    "        print(\"----------------------------------------------\")\n",
    "        print((current_score, \"Final\", selected))\n",
    "    formula = \"{} ~ {} + 1\".format(response, ' + '.join(list(selected)))\n",
    "    model = smf.logit(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea6422",
   "metadata": {},
   "source": [
    "La mise en oeuvre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab415b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelefinal = logitbackward(spam,\"Y~X0+X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17+X18+X19+X20+X21+X22+X23+X24+X25+X26+X27+X28+X29+X30+X31+X32+X33+X34+X35+X36+X37+X38+X39+X40+X41+X42+X43+X44+X45+X46+X47+X48+X49+X50+X51+X52+X53+X54+X55+X56\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef92d12",
   "metadata": {},
   "source": [
    "Le modèle sélectionné\n",
    "\n",
    "```{code-cell} python\n",
    "print(modelefinal.summary())\n",
    "```"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
